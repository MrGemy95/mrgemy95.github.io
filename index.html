<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>

        Mahmoud G. Salem

    </title>
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

    <!-- Open Graph -->

    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg=="
          crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css"
          integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q=="
          crossorigin="anonymous"/>

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
          integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog=="
          crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"
          integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg=="
          crossorigin="anonymous">
    <link rel="stylesheet" type="text/css"
          href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css"/>

    <!-- Styles -->

    <link rel="icon"
          href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="/">

    <!-- JQuery -->
    <!-- jQuery -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"
            integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg=="
            crossorigin="anonymous"></script>


    <!-- Theming-->

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>


    <!-- MathJax -->
    <script type="text/javascript">
        window.MathJax = {
            tex: {
                tags: 'ams'
            }
        };
    </script>
    <script defer type="text/javascript" id="MathJax-script"
            src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

</head>
<body class="fixed-top-nav ">

<!-- Header -->

<header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">

            <!-- Navbar Toggle -->
            <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse"
                    data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
                    aria-label="Toggle navigation">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar top-bar"></span>
                <span class="icon-bar middle-bar"></span>
                <span class="icon-bar bottom-bar"></span>
            </button>
            <div class="collapse navbar-collapse text-right" id="navbarNav">
                <ul class="navbar-nav ml-auto flex-nowrap">
                    <!-- About -->
                    <li class="nav-item active">
                        <a class="nav-link" href="/">
                            about
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>

                    <!-- Blog -->
                    <!--          <li class="nav-item ">-->
                    <!--            <a class="nav-link" href="/blog/">-->
                    <!--              blog-->

                    <!--            </a>-->
                    <!--          </li>-->

                    <!-- Other pages -->


                    <!--          <li class="nav-item ">-->
                    <!--              <a class="nav-link" href="/publications/">-->
                    <!--                publications-->

                    <!--              </a>-->
                    <!--          </li>-->


                    <div class="toggle-container">
                        <a id="light-toggle">
                            <i class="fas fa-moon"></i>
                            <i class="fas fa-sun"></i>
                        </a>
                    </div>

                </ul>
            </div>
        </div>
    </nav>

</header>

<!-- Content -->

<div class="container mt-5">
    <div class="post">

        <header class="post-header">
            <h1 class="post-title">
                <span class="font-weight-bold">Mahmoud</span> G. Salem
            </h1>
            <p class="clearfix"> I'm a MSc Student in Artificial Intelligence at University of Guelph and a student researcher at Vector Institute advised by <a href="https://www.gwtaylor.ca"> Dr. Graham Taylor </a>.

                During my MSc I was a research intern at <a href="https://www.sra.samsung.com"> Samusng Research</a> and   <a href="https://www.borealisai.com/en/research/publications/"> Borealis AI</a> winter 2021.

            Previously I was a research engineer at  <a href="https://www.navinfo.eu"> NavInfo Europe</a> for two years.  </p>

            <p class="clearfix">
                 <strong> Research Interests: </strong> Computer Vision, multi-modalities(vision+nlp), Model compression, Adversarial Robustness.
            </p>
        </header>

        <article>

            <div class="profile float-right">
                <img class="img-fluid z-depth-1 rounded-circle" src="/assets/img/pp.png">
            </div>


            <!-- <div class="clearfix">
              <p>Write your biography here. Tell the world about yourself. Link to your favorite <a href="http://reddit.com" target="\_blank">subreddit</a>. You can put a picture in, too. The code is already in, just name your picture <code class="language-plaintext highlighter-rouge">prof_pic.jpg</code> and put it in the <code class="language-plaintext highlighter-rouge">img/</code> folder.</p>

        <p>Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing <code class="language-plaintext highlighter-rouge">profile</code> property of the YAML header of your <code class="language-plaintext highlighter-rouge">_pages/about.md</code>. Edit <code class="language-plaintext highlighter-rouge">_bibliography/papers.bib</code> and Jekyll will render your <a href="/publications/">publications page</a> automatically.</p>

        <p>Link to your social media connections, too. This theme is set up to use <a href="http://fortawesome.github.io/Font-Awesome/" target="\_blank">Font Awesome icons</a> and <a href="https://jpswalsh.github.io/academicons/" target="\_blank">Academicons</a>, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.</p>

            </div> -->


            <div class="news">
                <h2>news</h2>

                <div class="table-responsive">
                    <table class="table table-sm table-borderless">


                        <tr>
                            <th scope="row">April, 2020</th>
                            <td>

                            </td>
                        </tr>

                        <tr>
                            <th scope="row">Nov 7, 2015</th>
                            <td>

                                <!-- <a class="news-title" href="/news/announcement_2/">A long announcement with details</a> -->

                            </td>
                        </tr>

                        <tr>
                            <th scope="row">Oct 22, 2015</th>
                            <td>

                                <!-- A simple inline announcement. -->


                            </td>
                        </tr>

                    </table>
                </div>

            </div>


            <div class="publications">
                <h2>Publications</h2>
                <ol class="bibliography">
                    <li>
                        <div class="row">
                            <div class="col-sm-2 abbr">
                                <abbr class="badge">ICRA</abbr>
                            </div>

                            <div id="pub1" class="col-sm-8">
                                <div class="title"> Video object segmentation using teacher-student adaptation in a
                                    human robot interaction (hri) setting
                                </div>
                                <div class="author">
                                    M Siam, C Jiang, S Lu, L Petrich, M Gamal, M Elhoseiny, M Jagersand
                                </div>

                                <div class="periodical">

                                    <em>ICRA</em>
                                    2019
                                </div>
                                <div class="links">
                                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                                    <a href="https://arxiv.org/pdf/1810.07733.pdf" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank">PDF</a>
                                </div>

                                <!-- Hidden abstract block -->

                                <div class="abstract hidden">
                                    <p>Abstract‚ÄîVideo object segmentation is an essential task in robot manipulation to
                                        facilitate grasping and learning affordances. Incremental learning is important
                                        for robotics in unstructured environments. Inspired by the children learning
                                        process, human robot interaction (HRI) can be utilized to teach robots about the
                                        world guided by humans similar to how children learn from a parent or a teacher.
                                        A human teacher can show potential objects of interest to the robot, which is
                                        able to self adapt to the teaching signal without providing man- ual
                                        segmentation labels. We propose a novel teacher-student learning paradigm to
                                        teach robots about their surrounding environment. A two-stream motion and
                                        appearance ‚Äùteacher‚Äù network provides pseudo-labels to adapt an appearance ‚Äùstu-
                                        dent‚Äù network. The student network is able to segment the newly learned objects
                                        in other scenes, whether they are static or in motion. We also introduce a
                                        carefully designed dataset that serves the proposed HRI setup, denoted as
                                        (I)nteractive (V)ideo (O)bject (S)egmentation. Our IVOS dataset contains
                                        teaching videos of different objects, and manipulation tasks. Our proposed
                                        adaptation method outperforms the state-of-the- art on DAVIS and FBMS with 6.8%
                                        and 1.2% in F-measure respectively. It improves over the baseline on IVOS
                                        dataset with 46.1% and 25.9% in mIoU.</p>
                                </div>

                                <!-- Hidden bibtex block -->
                            </div>
                        </div>


                        <div class="row">
                            <div class="col-sm-2 abbr">
                                <abbr class="badge">Neurips</abbr>
                            </div>

                            <div id="pub1" class="col-sm-8">
                                <div class="title"> End-To-End multi-modal sensors fusion system for urban automated
                                    driving
                                </div>
                                <div class="author">
                                    Ibrahim Sobh, Loay Amin, Sherif Abdelkarim, Khaled Elmadawy, Mahmoud Saeed, Omar
                                    Abdeltawab, Mostafa Gamal, Ahmad El Sallab
                                </div>

                                <div class="periodical">

                                    <em>Neurips workshop</em>
                                    2019
                                </div>

                                <div class="links">
                                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                                    <a href="https://openreview.net/pdf?id=Byx4Xkqjcm" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank">PDF</a>
                                </div>

                                <!-- Hidden abstract block -->

                                <div class="abstract hidden">
                                    <p>In this paper, we present a novel framework for urban automated driving based on
                                        multi-modal sensors; LiDAR and Camera. Environment perception through sensors
                                        fusion is key to successful deployment of automated driving systems, especially
                                        in complex urban areas. Our hypothesis is that a well designed deep neural
                                        network is able to end-to-end learn a driving policy that fuses LiDAR and Camera
                                        sensory input, achieving the best out of both. In order to improve the
                                        generalization and robustness of the learned policy, semantic segmentation on
                                        camera is applied, in addition to applying our new LiDAR post processing method;
                                        Polar Grid Mapping (PGM). The system is evaluated on the recently released urban
                                        car simulator, CARLA. The evaluation is measured according to the generalization
                                        performance from one environment to another. The experimental results show that
                                        the best performance is achieved by fusing the PGM and semantic
                                        segmentation.</p>
                                </div>

                                <!-- Hidden bibtex block -->
                            </div>
                        </div>


                        <div class="row">
                            <div class="col-sm-2 abbr">
                                <abbr class="badge">ICML</abbr>
                            </div>

                            <div id="pub1" class="col-sm-8">
                                <div class="title"> Meta learning Framework for Automated Driving
                                </div>
                                <div class="author">
                                    Ahmad El Sallab, Mahmoud Saeed, Omar Abdel Tawab, Mohammed Abdou
                                </div>

                                <div class="periodical">

                                    <em>ICML workshop</em>
                                    2017
                                </div>

                                <div class="links">
                                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                                    <a href="https://arxiv.org/pdf/1706.04038.pdf" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank">PDF</a>
                                </div>

                                <!-- Hidden abstract block -->

                                <div class="abstract hidden">
                                    <p>
                                        The success of automated driving deployment is highly depending on the ability
                                        to develop an efficient and safe driving policy. The prob- lem is well
                                        formulated under the framework of optimal control as a cost optimization
                                        problem. Model based solutions using traditional planning are efficient, but
                                        require the knowledge of the environment model. On the other hand, model free
                                        solutions suffer sample inefficiency and re- quire too many interactions with
                                        the environ- ment, which is infeasible in practice. Meth- ods under the
                                        Reinforcement Learning frame- work usually require the notion of a reward func-
                                        tion, which is not available in the real world. Im- itation learning helps in
                                        improving sample effi- ciency by introducing prior knowledge obtained from the
                                        demonstrated behavior, on the risk of exact behavior cloning without
                                        generalizing to unseen environments. In this paper we propose a Meta learning
                                        framework, based on data set ag- gregation, to improve generalization of
                                        imitation learning algorithms. Under the proposed frame- work, we propose
                                        MetaDAgger, a novel algo- rithm which tackles the generalization issues in
                                        traditional imitation learning. We use The Open Race Car Simulator (TORCS) to
                                        test our algo- rithm. Results on unseen test tracks show sig- nificant
                                        improvement over traditional imitation learning algorithms, improving the
                                        learning time and sample efficiency in the same time. The re- sults are also
                                        supported by visualization of the learnt features to prove generalization of the
                                        cap- tured details.</p>
                                </div>

                                <!-- Hidden bibtex block -->
                            </div>
                        </div>


                        <div class="row">
                            <div class="col-sm-2 abbr">
                                <abbr class="badge">AIxIA</abbr>
                            </div>

                            <div id="pub1" class="col-sm-8">
                                <div class="title"> Highlighting the Importance of Reducing Research Bias and Carbon
                                    Emissions in CNNs
                                </div>
                                <div class="author">
                                    Ahmed Badar, Arnav Varma, Adrian Staniec, Mahmoud Gamal, Omar Magdy, Haris Iqbal,
                                    Elahe Arani, Bahram Zonooz
                                </div>

                                <div class="periodical">

                                    <em>AIxIA</em>
                                    2021
                                </div>

                                <div class="links">
                                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                                    <a href="https://arxiv.org/pdf/2106.03242" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank">PDF</a>
                                </div>

                                <!-- Hidden abstract block -->

                                <div class="abstract hidden">
                                    <p>Convolutional neural networks (CNNs) have become commonplace in addressing major
                                        challenges in computer vision. Researchers are not only coming up with new CNN
                                        architectures but are also researching different techniques to improve the
                                        performance of existing architectures. However, there is a tendency to
                                        over-emphasize performance improvement while neglecting certain important
                                        variables such as simplicity, versatility, the fairness of comparisons, and
                                        energy efficiency. Overlooking these variables in architectural design and
                                        evaluation has led to research bias and a significantly negative environmental
                                        impact. Furthermore, this can undermine the positive impact of research in using
                                        deep learning models to tackle climate change. Here, we perform an extensive and
                                        fair empirical study of a number of proposed techniques to gauge the utility of
                                        each technique for segmentation and classification. Our findings restate the
                                        importance of favoring simplicity over complexity in model design (Occam's
                                        Razor). Furthermore, our results indicate that simple standardized practices can
                                        lead to a significant reduction in environmental impact with little drop in
                                        performance. We highlight that there is a need to rethink the design and
                                        evaluation of CNNs to alleviate the issue of research bias and carbon
                                        emissions.</p>
                                </div>

                                <!-- Hidden bibtex block -->
                            </div>
                        </div>
                    </li>
                </ol>
            </div>
        </article>
    </div>
</div>


<div class="social">
    <div class="contact-icons">
        <a href="mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D"><i class="fas fa-envelope"></i></a>


        <a href="https://scholar.google.com/citations?user=iN5_bwUAAAAJ&hl=en&amp;hl=en&amp;oi=ao" target="_blank"
           title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


        <a href="https://www.linkedin.com/in/mrgemy95/" target="_blank" title="LinkedIn"><i
                class="fab fa-linkedin"></i></a>
        <a href="https://twitter.com/mrgemy95" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>


        <!--        </div>-->
        <!--        <div class="contact-note">You can even add a little note about which of these is the best way to reach you.-->
        <!--        </div>-->

    </div>

    </article>

</div>

</div>

<!-- Footer -->


<footer class="fixed-bottom">
    <div class="container mt-0">
        ¬© Copyright 2021.
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a
            href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a
            href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a
            href="https://unsplash.com" target="_blank">Unsplash</a>.


    </div>
</footer>


</body>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js"
        integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A=="
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"
        integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ=="
        crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"
        integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw=="
        crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"
        integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>